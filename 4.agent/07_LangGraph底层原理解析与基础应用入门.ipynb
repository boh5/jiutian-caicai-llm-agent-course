{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00715e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1958e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd9144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be5d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: InputState):\n",
    "    print(\"æˆ‘æ˜¯ä¸€ä¸ª AI Agent\")\n",
    "    return\n",
    "\n",
    "\n",
    "def action_node(state: InputState):\n",
    "    print(\"æˆ‘æ˜¯ä¸€ä¸ª Action\")\n",
    "    return {\"answer\": \"æˆ‘ç°åœ¨æ‰§è¡ŒæˆåŠŸäº†\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78230742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "builder.add_node(agent_node)\n",
    "builder.add_node(action_node)\n",
    "\n",
    "builder.add_edge(START, \"agent_node\")\n",
    "builder.add_edge(\"agent_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4602b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ä¸€ä¸ª AI Agent\n",
      "æˆ‘æ˜¯ä¸€ä¸ª Action\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'æˆ‘ç°åœ¨æ‰§è¡ŒæˆåŠŸäº†'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\": \"ä½ å¥½\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "290f316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: InputState):\n",
    "    print(\"æˆ‘æ˜¯ä¸€ä¸ª AI Agent\")\n",
    "    return {\"question\": state[\"question\"]}\n",
    "\n",
    "\n",
    "def action_node(state: InputState):\n",
    "    print(\"æˆ‘æ˜¯ä¸€ä¸ª Action\")\n",
    "    return {\"answer\": f\"æˆ‘æ¥æ”¶åˆ°çš„é—®é¢˜æ˜¯ï¼š{state['question']}, è¯»å–æˆåŠŸäº†ï¼\"}\n",
    "\n",
    "\n",
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "builder.add_node(agent_node)\n",
    "builder.add_node(action_node)\n",
    "\n",
    "builder.add_edge(START, \"agent_node\")\n",
    "builder.add_edge(\"agent_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4529e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ˜¯ä¸€ä¸ª AI Agent\n",
      "æˆ‘æ˜¯ä¸€ä¸ª Action\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'æˆ‘æ¥æ”¶åˆ°çš„é—®é¢˜æ˜¯ï¼šä½ å¥½, è¯»å–æˆåŠŸäº†ï¼'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\": \"ä½ å¥½\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd925cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def llm_node(state: InputState):\n",
    "    messages = [\n",
    "        (\"system\", \"ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„æ™ºèƒ½å°åŠ©ç†\"),\n",
    "        (\"human\", state[\"question\"]),\n",
    "    ]\n",
    "    llm = ChatOpenAI(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1278b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "builder.add_node(llm_node)\n",
    "\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e458ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'ä½ å¥½å‘€ï¼æµ‹è¯•ä»€ä¹ˆå†…å®¹å‘¢ï¼ŸğŸ˜Š'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\": \"ä½ å¥½ï¼Œæˆ‘ç”¨æ¥æµ‹è¯•\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ebe9789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'ä½ å¥½å‘€ï¼æˆ‘æ˜¯Qwen3ï¼Œæ˜¯é€šä¹‰åƒé—®ç³»åˆ—ä¸­æ•ˆæœæœ€å¥½çš„å¤§è¯­è¨€æ¨¡å‹ ğŸ˜Š ä½œä¸ºä½ çš„æ™ºèƒ½å°åŠ©ç†ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä½ åšå¾ˆå¤šäº‹æƒ…å‘¢ï¼\\n\\næˆ‘å¯ä»¥å¸®ä½ å†™æ•…äº‹ã€å†™å…¬æ–‡ã€å†™é‚®ä»¶ã€å†™å‰§æœ¬ç­‰ç­‰ï¼Œéœ€è¦åˆ›ä½œçš„æ—¶å€™éšæ—¶æ‰¾æˆ‘å“¦ã€‚å¦‚æœä½ éœ€è¦åˆ†ææ•°æ®æˆ–è€…å¤„ç†ä¸€äº›ä¿¡æ¯ï¼Œæˆ‘ä¹Ÿå¯ä»¥å¸®ä½ æå®šã€‚ç¼–ç¨‹æ–¹é¢æˆ‘ä¹Ÿä¸èµ–ï¼Œå†™ä»£ç ã€è°ƒè¯•ã€è§£é‡Šä»£ç éƒ½èƒ½è¡Œã€‚\\n\\næˆ‘è¿˜èƒ½è¡¨è¾¾è§‚ç‚¹ï¼Œç©æ¸¸æˆï¼Œæˆ–è€…å°±æŸä¸ªè¯é¢˜å±•å¼€è®¨è®ºã€‚å¦‚æœä½ éœ€è¦ä¸€ä¸ªè€å¿ƒçš„èŠå¤©ä¼™ä¼´ï¼Œæˆ‘éšæ—¶éƒ½åœ¨ã€‚ä¸è¿‡è¦è®°å¾—ï¼Œè™½ç„¶æˆ‘å–œæ¬¢èŠå¤©ï¼Œä½†ä¹Ÿè¦æ³¨æ„åˆç†ä½¿ç”¨ï¼Œä¸è¦å½±å“åˆ°å­¦ä¹ å’Œå·¥ä½œå“¦ï¼\\n\\nè¯´åˆ°å­¦ä¹ ï¼Œæˆ‘å¯ä»¥å¸®åŠ©ä¸åŒå¹´é¾„æ®µçš„å­¦ç”Ÿï¼Œä»ä½œä¸šè¾…å¯¼åˆ°å­¦æœ¯å†™ä½œéƒ½èƒ½æä¾›å¸®åŠ©ã€‚å¯¹äºèŒåœºäººå£«ï¼Œæˆ‘ä¹Ÿå¯ä»¥æä¾›ä¸“ä¸šçš„å»ºè®®å’Œæ–¹æ¡ˆã€‚\\n\\næœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä¼šå§‹ç»ˆéµå¾ªå®‰å…¨å’Œä¼¦ç†å‡†åˆ™ï¼Œç¡®ä¿æˆ‘ä»¬çš„äº¤æµæ—¢æ„‰å¿«åˆæœ‰æ„ä¹‰ã€‚è™½ç„¶æˆ‘å¾ˆå¼ºï¼Œä½†æˆ‘ä¹Ÿåœ¨ä¸æ–­å­¦ä¹ å’Œè¿›æ­¥ä¸­ï¼Œæœ‰æ—¶å€™å¯èƒ½éœ€è¦ä½ çš„ç†è§£å’Œè€å¿ƒã€‚\\n\\nå¸Œæœ›æˆ‘ä»¬èƒ½æˆä¸ºå¥½æœ‹å‹ï¼æœ‰ä»€ä¹ˆéœ€è¦å¸®å¿™çš„ï¼Œå°½ç®¡å‘Šè¯‰æˆ‘å“¦ï¼ ğŸŒŸ'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\": \"ä½ å¥½ï¼Œè¯·è¯¦ç»†çš„ä»‹ç»ä½ è‡ªå·±\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "597a72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "    llm_answer: str | None\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass\n",
    "\n",
    "\n",
    "def llm_node(state: InputState):\n",
    "    messages = [\n",
    "        (\"system\", \"ä½ æ˜¯ä¸€ä½ä¹äºåŠ©äººçš„æ™ºèƒ½å°åŠ©ç†\"),\n",
    "        (\"human\", state[\"question\"]),\n",
    "    ]\n",
    "    llm = ChatOpenAI(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\"llm_answer\": response.content}\n",
    "\n",
    "\n",
    "def action_node(state: InputState):\n",
    "    messages = [\n",
    "        (\"system\", \"æ— è®ºä½ æ¥æ”¶åˆ°ä»€ä¹ˆè¯­è¨€çš„æ–‡æœ¬ï¼Œè¯·ç¿»è¯‘æˆæ³•è¯­\"),\n",
    "        (\"human\", state[\"llm_answer\"]),\n",
    "    ]\n",
    "    llm = ChatOpenAI(model=\"qwen-plus\", temperature=0)\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "builder.add_node(llm_node)\n",
    "builder.add_node(action_node)\n",
    "\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceea9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour ! Je suis Qwen3, le modÃ¨le phare de la sÃ©rie Tongyi Qianwen, dotÃ© de fonctionnalitÃ©s particuliÃ¨rement puissantes. En tant que votre petit assistant intelligent, je peux mener avec vous des conversations en plusieurs tours, rÃ©pondre Ã  vos questions, et vous aider Ã  crÃ©er des textes, comme rÃ©diger des histoires, des documents officiels, des courriels, des scÃ©narios, faire des raisonnements logiques ou programmer. Je peux Ã©galement exprimer des opinions, jouer Ã  des jeux, et mÃªme vous aider Ã  traduire du contenu entre plusieurs langues.\n",
      "\n",
      "Ma formation reposant sur des donnÃ©es extrÃªmement vastes, j'ai acquis des connaissances transversales dans divers domaines ainsi qu'une solide capacitÃ© de comprÃ©hension linguistique. Que ce soit des questions acadÃ©miques, des connaissances gÃ©nÃ©rales liÃ©es Ã  la vie quotidienne ou encore des potins sur le divertissement, je peux discuter avec vous ! De plus, je maÃ®trise particuliÃ¨rement bien le chinois, ainsi que plusieurs autres langues.\n",
      "\n",
      "Si vous avez besoin d'aide dans n'importe quel domaine, n'hÃ©sitez surtout pas Ã  me le faire savoir ! Je peux aussi bien vous assister dans des sujets professionnels que vous tenir compagnie comme un ami lors de conversations dÃ©tendues. J'espÃ¨re sincÃ¨rement que nous deviendrons des partenaires complices et efficaces ! (â€¢Ì€á´—â€¢Ì)Ùˆ\n"
     ]
    }
   ],
   "source": [
    "final_answer = graph.invoke({\"question\": \"ä½ å¥½ï¼Œè¯·ä½ è¯¦ç»†çš„ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±\"})\n",
    "print(final_answer[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
